{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Shareable Jupyter Notebook for the Capstone project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Capstone Project Course!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('Hello Capstone Project Course!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction/Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem at hand is find a solution that can help predict the severity of an accident if an accident were to occur given various environmental information. This is to help potential stakeholders which in this case includes those that have to drive to get to their final destination every day. Given various inputs of a particular day, how can we determine if there will be an accident on the way to a destination? If we can find a method to answer this problem, we can give the stakeholders that insight of choosing a different method of transportation. Not only could this insight potentially offset any risk that the person would incur if they were the ones to get an accident, but it could also allow for their ability to reach their final destination within the time frame that they were expecting to due to not being stuck in traffic waiting for the situation to clear up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example dataset’s metadata file, we can see that it is for the relatively high density population within the city of Seattle, Washington. Within this dataset, we can see that it has 37 attributes that can be of interest, including ones that detail the weather, location and level of accidents, the road conditions, among many others. Since we are trying to determine the probability of an accident occurring, and how bad or severe of an accident it will be, we will use the severity attribute as the target variable within our model. In order to decide which attributes would be of most use or importance for the model building, I will apply a feature selection process by utilizing attributes that provide the most information gain on the data, given the target variable. In addition, this dataset also contains an abundance of over 70,000 samples or observations that we can use to train a machine learning model and test against. Since we’ll be working with classification, some classification models that come to mind that may be of use include building a Decision Tree, using K-Nearest Neighbors, Support Vector Machines, and/or Logistic Regression. Once I’ve built each model, I will do a model evaluation based on a couple of scoring mechanism such as the Jaccard Score, Average F1-Score, and LogLoss metrics to see which model performed the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodlogy/Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "#!conda install -c anaconda seaborn -y\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fperez/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCKEY</th>\n",
       "      <th>COLDETKEY</th>\n",
       "      <th>REPORTNO</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ADDRTYPE</th>\n",
       "      <th>INTKEY</th>\n",
       "      <th>...</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "      <th>PEDROWNOTGRNT</th>\n",
       "      <th>SDOTCOLNUM</th>\n",
       "      <th>SPEEDING</th>\n",
       "      <th>ST_COLCODE</th>\n",
       "      <th>ST_COLDESC</th>\n",
       "      <th>SEGLANEKEY</th>\n",
       "      <th>CROSSWALKKEY</th>\n",
       "      <th>HITPARKEDCAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-122.323148</td>\n",
       "      <td>47.703140</td>\n",
       "      <td>1</td>\n",
       "      <td>1307</td>\n",
       "      <td>1307</td>\n",
       "      <td>3502005</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>37475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Entering at angle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.347294</td>\n",
       "      <td>47.647172</td>\n",
       "      <td>2</td>\n",
       "      <td>52200</td>\n",
       "      <td>52200</td>\n",
       "      <td>2607959</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Block</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6354039.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>From same direction - both going straight - bo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.334540</td>\n",
       "      <td>47.607871</td>\n",
       "      <td>3</td>\n",
       "      <td>26700</td>\n",
       "      <td>26700</td>\n",
       "      <td>1482393</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Block</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4323031.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>One parked--one moving</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.334803</td>\n",
       "      <td>47.604803</td>\n",
       "      <td>4</td>\n",
       "      <td>1144</td>\n",
       "      <td>1144</td>\n",
       "      <td>3503937</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Block</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>From same direction - all others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-122.306426</td>\n",
       "      <td>47.545739</td>\n",
       "      <td>5</td>\n",
       "      <td>17700</td>\n",
       "      <td>17700</td>\n",
       "      <td>1807429</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Intersection</td>\n",
       "      <td>34387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4028032.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Entering at angle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITYCODE           X          Y  OBJECTID  INCKEY  COLDETKEY REPORTNO  \\\n",
       "0             2 -122.323148  47.703140         1    1307       1307  3502005   \n",
       "1             1 -122.347294  47.647172         2   52200      52200  2607959   \n",
       "2             1 -122.334540  47.607871         3   26700      26700  1482393   \n",
       "3             1 -122.334803  47.604803         4    1144       1144  3503937   \n",
       "4             2 -122.306426  47.545739         5   17700      17700  1807429   \n",
       "\n",
       "    STATUS      ADDRTYPE   INTKEY  ... ROADCOND                LIGHTCOND  \\\n",
       "0  Matched  Intersection  37475.0  ...      Wet                 Daylight   \n",
       "1  Matched         Block      NaN  ...      Wet  Dark - Street Lights On   \n",
       "2  Matched         Block      NaN  ...      Dry                 Daylight   \n",
       "3  Matched         Block      NaN  ...      Dry                 Daylight   \n",
       "4  Matched  Intersection  34387.0  ...      Wet                 Daylight   \n",
       "\n",
       "  PEDROWNOTGRNT  SDOTCOLNUM SPEEDING ST_COLCODE  \\\n",
       "0           NaN         NaN      NaN         10   \n",
       "1           NaN   6354039.0      NaN         11   \n",
       "2           NaN   4323031.0      NaN         32   \n",
       "3           NaN         NaN      NaN         23   \n",
       "4           NaN   4028032.0      NaN         10   \n",
       "\n",
       "                                          ST_COLDESC  SEGLANEKEY  \\\n",
       "0                                  Entering at angle         0.0   \n",
       "1  From same direction - both going straight - bo...         0.0   \n",
       "2                             One parked--one moving         0.0   \n",
       "3                   From same direction - all others         0.0   \n",
       "4                                  Entering at angle         0.0   \n",
       "\n",
       "   CROSSWALKKEY  HITPARKEDCAR  \n",
       "0           0.0             N  \n",
       "1           0.0             N  \n",
       "2           0.0             N  \n",
       "3           0.0             N  \n",
       "4           0.0             N  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = pd.read_csv(r'Data-Collisions.csv')\n",
    "#Checking Null Values\n",
    "(dc[\"ROADCOND\"].isnull()==True).sum()\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.dtypes\n",
    "set(dc['SEVERITYCODE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = ['SEVERITYCODE', 'OBJECTID', 'INCDTTM', 'WEATHER','ROADCOND','LIGHTCOND','SPEEDING']\n",
    "df = dc[Features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing accidents where there is missing times decreased the number of total observations significantly. May need to add it back and just remove using the date and time.\n",
    "\n",
    "Want to use SeverityCode 0 to remove unknown records, speeding to remove accidents caused by speeding since its not an environemntal cause, Remove observations with missing data on Road Conditions, Light Condtions, and weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fperez/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67591, 6)\n",
      "(67018, 6)\n",
      "(66972, 6)\n",
      "(66893, 6)\n"
     ]
    }
   ],
   "source": [
    "df['INCDTTM'] = pd.to_datetime(df['INCDTTM'])\n",
    "\n",
    "#Removing Null Times/Separating Date&Time Column into 2.\n",
    "##print(df.shape)\n",
    "##dtna_con = (df['INCDTTM'].isnull()==True)\n",
    "##df = df.loc[~(dtna_con),:]\n",
    "##print(df.shape)\n",
    "\n",
    "#Removing Timestamps (?)\n",
    "#timena_con =(df['INCDTTM'].apply(lambda x: str(x.time())!= \"00:00:00\"))\n",
    "#df = df.loc[timena_con,:]\n",
    "\n",
    "##df['Date'],df['Time'] = df['INCDTTM'].apply(lambda x:x.date()),df['INCDTTM'].apply(lambda x:x.time())\n",
    "\n",
    "##df.drop('INCDTTM', axis=1, inplace=True)\n",
    "##print(df.shape)\n",
    "\n",
    "#Now removing accidents caused by speeding specifically\n",
    "spd_con = (df['SPEEDING'].apply(lambda x:x=='Y'))\n",
    "df = df.loc[(~spd_con),:]\n",
    "df.drop('SPEEDING', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "#Removing samples wth no weather data\n",
    "weather_con = (df['WEATHER'].apply(lambda x: pd.isnull(x)==True\\\n",
    "                    #or x=='Unknown'\\\n",
    "                    or x=='Other')\\\n",
    "                    )\n",
    "\n",
    "df = df.loc[(~weather_con),:]\n",
    "print(df.shape)\n",
    "\n",
    "#Removing samples wth no Road Condition data\n",
    "road_con = (df['ROADCOND'].apply(lambda x: pd.isnull(x)==True\\\n",
    "                    #or x=='Unknown'\\\n",
    "                    or x=='Other')\\\n",
    "                    )\n",
    "\n",
    "df = df.loc[(~road_con),:]\n",
    "print(df.shape)\n",
    "\n",
    "#Removing samples wth no Lighting Condition data\n",
    "light_con = (df['LIGHTCOND'].apply(lambda x: pd.isnull(x)==True\\\n",
    "                    #or x=='Unknown'\\\n",
    "                    or x=='Other')\\\n",
    "                    )\n",
    "\n",
    "df = df.loc[~(light_con),:]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the current SeverityCodes in the dataset\n",
    "#print(set(df['SEVERITYCODE'].values))\n",
    "#road_con = (df['LIGHTCOND'].apply(lambda x: pd.isnull(x)==True\\\n",
    "#                    or x=='Unknown'\\\n",
    "#                    or x=='Other')\\\n",
    "#                    )\n",
    "#road_con.sum()\n",
    "\n",
    "#(df['SPEEDING'].apply(lambda x:np.isnan(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCDTTM</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-27 14:54:00</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-12-20 18:55:00</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-11-18 10:20:00</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-29 09:26:00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-01-28 08:04:00</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITYCODE  OBJECTID             INCDTTM   WEATHER ROADCOND  \\\n",
       "0             2         1 2013-03-27 14:54:00  Overcast      Wet   \n",
       "1             1         2 2006-12-20 18:55:00   Raining      Wet   \n",
       "2             1         3 2004-11-18 10:20:00  Overcast      Dry   \n",
       "3             1         4 2013-03-29 09:26:00     Clear      Dry   \n",
       "4             2         5 2004-01-28 08:04:00   Raining      Wet   \n",
       "\n",
       "                 LIGHTCOND  \n",
       "0                 Daylight  \n",
       "1  Dark - Street Lights On  \n",
       "2                 Daylight  \n",
       "3                 Daylight  \n",
       "4                 Daylight  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding which months have the most accidents\n",
    "##df['Month'] = pd.to_datetime(df['Date']).dt.month.values\n",
    "##df['Month'].head()\n",
    "##df['Dayofweek'] = pd.to_datetime(df['Date']).dt.dayofweek\n",
    "df.head()\n",
    "\n",
    "#bins = np.linspace(df.Dayofweek.min(), df.Dayofweek.max(), 10)\n",
    "#g = sns.FacetGrid(df, col=\"Month\", hue=\"SEVERITYCODE\", palette=\"Set1\", col_wrap=2)\n",
    "#g.map(plt.hist, 'Dayofweek', bins=bins, ec=\"k\")\n",
    "#g.axes[-1].legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66893, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blowing Sand/Dirt</th>\n",
       "      <th>Clear</th>\n",
       "      <th>Fog/Smog/Smoke</th>\n",
       "      <th>Overcast</th>\n",
       "      <th>Raining</th>\n",
       "      <th>Severe Crosswind</th>\n",
       "      <th>Sleet/Hail/Freezing Rain</th>\n",
       "      <th>Snowing</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Dry</th>\n",
       "      <th>...</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wet</th>\n",
       "      <th>Dark - No Street Lights</th>\n",
       "      <th>Dark - Street Lights Off</th>\n",
       "      <th>Dark - Street Lights On</th>\n",
       "      <th>Dark - Unknown Lighting</th>\n",
       "      <th>Dawn</th>\n",
       "      <th>Daylight</th>\n",
       "      <th>Dusk</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blowing Sand/Dirt  Clear  Fog/Smog/Smoke  Overcast  Raining  \\\n",
       "0                  0      0               0         1        0   \n",
       "1                  0      0               0         0        1   \n",
       "2                  0      0               0         1        0   \n",
       "3                  0      1               0         0        0   \n",
       "4                  0      0               0         0        1   \n",
       "\n",
       "   Severe Crosswind  Sleet/Hail/Freezing Rain  Snowing  Unknown  Dry  ...  \\\n",
       "0                 0                         0        0        0    0  ...   \n",
       "1                 0                         0        0        0    0  ...   \n",
       "2                 0                         0        0        0    1  ...   \n",
       "3                 0                         0        0        0    1  ...   \n",
       "4                 0                         0        0        0    0  ...   \n",
       "\n",
       "   Unknown  Wet  Dark - No Street Lights  Dark - Street Lights Off  \\\n",
       "0        0    1                        0                         0   \n",
       "1        0    1                        0                         0   \n",
       "2        0    0                        0                         0   \n",
       "3        0    0                        0                         0   \n",
       "4        0    1                        0                         0   \n",
       "\n",
       "   Dark - Street Lights On  Dark - Unknown Lighting  Dawn  Daylight  Dusk  \\\n",
       "0                        0                        0     0         1     0   \n",
       "1                        1                        0     0         0     0   \n",
       "2                        0                        0     0         1     0   \n",
       "3                        0                        0     0         1     0   \n",
       "4                        0                        0     0         1     0   \n",
       "\n",
       "   Unknown  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature2 = pd.concat([# \\df[[\"Month\"]],\\\n",
    "                     pd.get_dummies(df['WEATHER']),\\\n",
    "                     pd.get_dummies(df['ROADCOND']),\\\n",
    "                     pd.get_dummies(df['LIGHTCOND'])],\\\n",
    "                     axis=1)\n",
    "X = Feature2\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['SEVERITYCODE'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01813813, -1.22212451, -0.04896544,  2.35050488, -0.44398861,\n",
       "        -0.01222763, -0.0262324 , -0.06987293, -0.28410339, -1.46380655,\n",
       "        -0.08375691, -0.01933574, -0.02255067, -0.07736545, -0.0222164 ,\n",
       "        -0.26919742,  1.79758836, -0.09146718, -0.08090419, -0.57838023,\n",
       "        -0.00386645, -0.1134478 ,  0.77161353, -0.18754964, -0.25492865],\n",
       "       [-0.01813813, -1.22212451, -0.04896544, -0.42544051,  2.25231006,\n",
       "        -0.01222763, -0.0262324 , -0.06987293, -0.28410339, -1.46380655,\n",
       "        -0.08375691, -0.01933574, -0.02255067, -0.07736545, -0.0222164 ,\n",
       "        -0.26919742,  1.79758836, -0.09146718, -0.08090419,  1.72896643,\n",
       "        -0.00386645, -0.1134478 , -1.29598557, -0.18754964, -0.25492865],\n",
       "       [-0.01813813, -1.22212451, -0.04896544,  2.35050488, -0.44398861,\n",
       "        -0.01222763, -0.0262324 , -0.06987293, -0.28410339,  0.68315038,\n",
       "        -0.08375691, -0.01933574, -0.02255067, -0.07736545, -0.0222164 ,\n",
       "        -0.26919742, -0.55630089, -0.09146718, -0.08090419, -0.57838023,\n",
       "        -0.00386645, -0.1134478 ,  0.77161353, -0.18754964, -0.25492865],\n",
       "       [-0.01813813,  0.81824724, -0.04896544, -0.42544051, -0.44398861,\n",
       "        -0.01222763, -0.0262324 , -0.06987293, -0.28410339,  0.68315038,\n",
       "        -0.08375691, -0.01933574, -0.02255067, -0.07736545, -0.0222164 ,\n",
       "        -0.26919742, -0.55630089, -0.09146718, -0.08090419, -0.57838023,\n",
       "        -0.00386645, -0.1134478 ,  0.77161353, -0.18754964, -0.25492865],\n",
       "       [-0.01813813, -1.22212451, -0.04896544, -0.42544051,  2.25231006,\n",
       "        -0.01222763, -0.0262324 , -0.06987293, -0.28410339, -1.46380655,\n",
       "        -0.08375691, -0.01933574, -0.02255067, -0.07736545, -0.0222164 ,\n",
       "        -0.26919742,  1.79758836, -0.09146718, -0.08090419, -0.57838023,\n",
       "        -0.00386645, -0.1134478 ,  0.77161353, -0.18754964, -0.25492865]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Model Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\\\n",
    "                 horizontalalignment=\"center\",\\\n",
    "                 verticalalignment=\"bottom\",\\\n",
    "                 fontsize = 16,\\\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (56859, 25) (56859,)\n",
      "Testing set:  (10034, 25) (10034,)\n",
      "\n",
      "Due to unbalanced dataset, we'll be using Stratified training and test sets:\n",
      "\n",
      "Proportion of Severity Level 1 in Training set is 0.71 and \n",
      "Proportion of Severity Level 2 in Training set is 0.29.\n",
      "\n",
      "Proportion of Severity Level 1 in Testing set is 0.71 and \n",
      "Proportion of Severity Level 2 in Testing set is 0.29.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,\\\n",
    "                                                    stratify=y, random_state=2)\n",
    "\n",
    "print('Training set: ', X_train.shape, y_train.shape)\n",
    "print('Testing set: ', X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nDue to unbalanced dataset, we'll be using Stratified training and test sets:\\n\")\n",
    "print(\"Proportion of Severity Level 1 in Training set is %.2f and \\n\"\\\n",
    "      % ((y_train==1).sum()/y_train.shape[0]) +\\\n",
    "     \"Proportion of Severity Level 2 in Training set is %.2f.\\n\"\\\n",
    "      % ((y_train==2).sum()/y_train.shape[0]) )\n",
    "\n",
    "print(\"Proportion of Severity Level 1 in Testing set is %.2f and \\n\"\\\n",
    "      % ((y_test==1).sum()/y_test.shape[0]) +\\\n",
    "     \"Proportion of Severity Level 2 in Testing set is %.2f.\\n\"\\\n",
    "      % ((y_test==2).sum()/y_test.shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In addition, I will also be attempting oversampling for the minority dataset to see if I can improve the model further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81296, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = ros.fit_resample(X_train, y_train)\n",
    "X_over.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-68c04c9e13ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mKs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmean_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstd_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 delayed_query(\n\u001b[1;32m    664\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 665\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             )\n\u001b[1;32m    667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "Ks=10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat = neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "print(mean_acc)\n",
    "\n",
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n",
    "\n",
    "n = mean_acc.argmax()+1\n",
    "neighn = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "yhat_knn = neighn.predict(X_test)\n",
    "yhat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mat = confusion_matrix(y_test, yhat_knn, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_knn))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(knn_mat, classes=[1,2], normalize= False,  title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Oversampling of Minority Class (SEVERITYCODE=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "Ks=10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_over,y_over)\n",
    "    yhat = neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "print(mean_acc)\n",
    "\n",
    "plt.plot(range(1,Ks),mean_acc,'g')\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n",
    "\n",
    "n = mean_acc.argmax()+1\n",
    "neighnOver = KNeighborsClassifier(n_neighbors=n).fit(X_over, y_over)\n",
    "yhat_knnOver = neighnOver.predict(X_test)\n",
    "yhat_knnOver[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_matOver = confusion_matrix(y_test, yhat_knnOver, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_knnOver))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(knn_matOver, classes=[1,2], normalize= False,  title='Confusion matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Dps=50\n",
    "mean_acc_dp = np.zeros((Dps-1))\n",
    "std_acc_dp = np.zeros((Dps-1))\n",
    "\n",
    "for n in range(1,Dps):\n",
    "    accTree = DecisionTreeClassifier(criterion='entropy', max_depth=n).fit(X_train, y_train)\n",
    "    yhat_dp = accTree.predict(X_test)\n",
    "    mean_acc_dp[n-1] = metrics.accuracy_score(y_test, yhat_dp)\n",
    "    std_acc_dp[n-1]=np.std(yhat_dp==y_test)/np.sqrt(yhat_dp.shape[0])\n",
    "    \n",
    "print(mean_acc_dp)\n",
    "\n",
    "plt.plot(range(1,Dps),mean_acc_dp,'g')\n",
    "plt.fill_between(range(1,Dps), mean_acc_dp - 1 * std_acc_dp, mean_acc_dp + 1 * std_acc_dp, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Level of Depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", mean_acc_dp.max(), \"with Depth=\", mean_acc_dp.argmax()+1) \n",
    "n = 8\n",
    "DT1 = DecisionTreeClassifier(criterion='entropy', max_depth=n).fit(X_train, y_train)\n",
    "yhat_dt = DT1.predict(X_test)\n",
    "yhat_dt[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_mat = confusion_matrix(y_test, yhat_dt, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_dt))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(dt_mat, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Oversampling of Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dps=50\n",
    "mean_acc_dp = np.zeros((Dps-1))\n",
    "std_acc_dp = np.zeros((Dps-1))\n",
    "\n",
    "for n in range(1,Dps):\n",
    "    accTree = DecisionTreeClassifier(criterion='entropy', max_depth=n).fit(X_over, y_over)\n",
    "    yhat_dp = accTree.predict(X_test)\n",
    "    mean_acc_dp[n-1] = metrics.accuracy_score(y_test, yhat_dp)\n",
    "    std_acc_dp[n-1]=np.std(yhat_dp==y_test)/np.sqrt(yhat_dp.shape[0])\n",
    "    \n",
    "print(mean_acc_dp)\n",
    "\n",
    "plt.plot(range(1,Dps),mean_acc_dp,'g')\n",
    "plt.fill_between(range(1,Dps), mean_acc_dp - 1 * std_acc_dp, mean_acc_dp + 1 * std_acc_dp, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Level of Depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy using OVERSAMPLING was\", mean_acc_dp.max(), \"with Depth=\", mean_acc_dp.argmax()+1) \n",
    "n = mean_acc_dp.argmax()+1\n",
    "DT1Over = DecisionTreeClassifier(criterion='entropy', max_depth=n).fit(X_over, y_over)\n",
    "yhat_dtOver = DT1Over.predict(X_test)\n",
    "yhat_dtOver[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_matOver = confusion_matrix(y_test, yhat_dtOver, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_dtOver))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(dt_matOver, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM_acc = svm.SVC(kernel='rbf')\n",
    "SVM_acc.fit(X_train, y_train)\n",
    "yhat_svm = SVM_acc.predict(X_test)\n",
    "yhat_svm[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mat = confusion_matrix(y_test, yhat_svm, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_svm))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(svm_mat, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine with Oversampling Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_accOver = svm.SVC(kernel='rbf')\n",
    "SVM_accOver.fit(X_over, y_over)\n",
    "yhat_svmOver = SVM_accOver.predict(X_test)\n",
    "yhat_svmOver[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_matOver = confusion_matrix(y_test, yhat_svmOver, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_svmOver))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(svm_matOver, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lr = LR.predict(X_test)\n",
    "yhat_pb_lr = LR.predict_proba(X_test)\n",
    "yhat_lr[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mat = confusion_matrix(y_test, yhat_lr, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_lr))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(lr_mat, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Oversampling the Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LROver = LogisticRegression(C=0.01, solver='liblinear').fit(X_over, y_over)\n",
    "yhat_lrOver = LROver.predict(X_test)\n",
    "yhat_pb_lrOver = LROver.predict_proba(X_test)\n",
    "yhat_lrOver[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_matOver = confusion_matrix(y_test, yhat_lrOver, labels=[1,2])\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(classification_report(y_test, yhat_lrOver))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(lr_matOver, classes=[1,2], normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "#from sklearn.metrics import jaccard_similarity_score # Now Deprecated\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Jaccard and F1-Score Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_knn)\n",
    "print(\"KNN Jaccard score: %.4f\" % jaccard_score(y_test, yhat_knn))\n",
    "f1_score(y_test, yhat_knn, average='weighted')\n",
    "print(\"KNN Avg F1-score: %.4f\" % f1_score(y_test, yhat_knn, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Oversampling Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_knnOver)\n",
    "print(\"KNN (Oversampling) Jaccard score: %.4f\" % jaccard_score(y_test, yhat_knnOver))\n",
    "f1_score(y_test, yhat_knnOver, average='weighted')\n",
    "print(\"KNN (Oversampling) Avg F1-score: %.4f\" % f1_score(y_test, yhat_knnOver, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Jaccard and F1-Score Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_dt)\n",
    "print(\"Decision Tree Jaccard score: %.4f\" % jaccard_score(y_test, yhat_dt))\n",
    "f1_score(y_test, yhat_dt, average='weighted')\n",
    "print(\"Decision Tree Avg F1-score: %.4f\" % f1_score(y_test, yhat_dt, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Oversampling Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_dtOver)\n",
    "print(\"Decision Tree (Oversampling) Jaccard score: %.4f\" % jaccard_score(y_test, yhat_dtOver))\n",
    "f1_score(y_test, yhat_dtOver, average='weighted')\n",
    "print(\"Decision Tree (Oversampling) Avg F1-score: %.4f\" % f1_score(y_test, yhat_dtOver, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Jaccard and F1-Score Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_svm)\n",
    "print(\"SVM Jaccard score: %.4f\" % jaccard_score(y_test, yhat_svm))\n",
    "f1_score(y_test, yhat_svm, average='weighted')\n",
    "print(\"SVM Avg F1-score: %.4f\" % f1_score(y_test, yhat_svm, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Oversampling Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_svmOver)\n",
    "print(\"SVM Oversampling Jaccard score: %.4f\" % jaccard_score(y_test, yhat_svmOver))\n",
    "f1_score(y_test, yhat_svmOver, average='weighted')\n",
    "print(\"SVM Oversampling Avg F1-score: %.4f\" % f1_score(y_test, yhat_svmOver, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Jaccard, F1-Score, and LogLoss Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_lr)\n",
    "print(\"Logistic Regression Jaccard score: %.4f\" % jaccard_score(y_test, yhat_lr))\n",
    "f1_score(y_test, yhat_lr, average='weighted')\n",
    "print(\"Logistic Regression Avg F1-score: %.4f\" % f1_score(y_test, yhat_lr, average='weighted'))\n",
    "yhat_Testprob = LR.predict_proba(X_test)\n",
    "#yhat_Testprob\n",
    "log_loss(y_test, yhat_Testprob)\n",
    "print(\"Logistic Regression LogLoss: %.2f\" % log_loss(y_test, yhat_Testprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, yhat_lrOver)\n",
    "print(\"Logistic Regression Jaccard score: %.4f\" % jaccard_score(y_test, yhat_lrOver))\n",
    "f1_score(y_test, yhat_lrOver, average='weighted')\n",
    "print(\"Logistic Regression Avg F1-score: %.4f\" % f1_score(y_test, yhat_lrOver, average='weighted'))\n",
    "yhat_TestprobOver = LROver.predict_proba(X_test)\n",
    "#yhat_Testprob\n",
    "log_loss(y_test, yhat_TestprobOver)\n",
    "print(\"Logistic Regression LogLoss: %.2f\" % log_loss(y_test, yhat_TestprobOver))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
